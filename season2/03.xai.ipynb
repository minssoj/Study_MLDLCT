{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "colab": {
   "name": "Chapter 02. (정답시트) 설명가능한 머신러닝 (1)",
   "provenance": [
    {
     "file_id": "1rVgp4RPMOr1-EeOsMjrPr_RipxRaHNHP",
     "timestamp": 1616040939505
    },
    {
     "file_id": "1Z2vhWiHKviErxxN5HKcINKdDgkEKlE1T",
     "timestamp": 1613576628084
    },
    {
     "file_id": "1306Az_uyQBbiZbpIlG2bsoYiwgPtpJo8",
     "timestamp": 1613567949837
    }
   ],
   "collapsed_sections": [
    "xQFWdtfAMg8X",
    "GIJnp2oyMg8Y",
    "mZktOBVzMg8a",
    "1RI3BfxJMg8c",
    "k_Rxx8t6Mg8d",
    "jx0Tq9YtMg8d",
    "t4-2NkUsMg8g",
    "xMf51TSUMg8h",
    "9fzzeI4wMg8l",
    "GUPTHvxjMg8n",
    "VEjD5K1fMg8p",
    "bnBJUhceMg8q",
    "IhoVmPc2Mg8t",
    "IBpJcuCmMg8y",
    "iZDHBXTNMg80",
    "iOVkbs5sMg83",
    "ssacPRGuMg84",
    "Wbv_PjNKMg87",
    "5TZKEvtYMg87",
    "hSf1TYPwMg87",
    "XNGt63SHMg9o"
   ]
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "0. 학습 환결 설정하기\n",
    "1. 데이터셋 불러오기\n",
    "2. 모델 회귀계수 확인하기\n",
    "3. 모델 피처 중요도 분석하기\n",
    "* 출제자: 최민정 강사 (패스트캠퍼스)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. 학습 환경 설정하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle ## 데이터 모델 저장하기, 불러오기\n",
    "import gzip ## 파일 압축하기, 압축풀기\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datapath = 'https://github.com/mchoimis/financialML/raw/main/xai/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! mkdir financialml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cd /content/gdrive/My Drive/Colab Notebooks/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 데이터셋 불러오기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 및 데이터 설명\n",
    "\n",
    "- `data00` : 이진분류용 데이터\n",
    "\n",
    "- `data01` : 다중분류용 데이터\n",
    "\n",
    "- `logreg` : Logistic Regression Classifier (`00`)\n",
    "\n",
    "- `rfc`    : Random Forest Classifier (`00`, `01`)\n",
    "\n",
    "- `gbc`    : Gradient Boosting Classifier (`00`)\n",
    "\n",
    "- `lgbm`   : LightGBM Classifier (`00`, `01`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelpath = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "\n",
    "with gzip.open(modelpath + 'data00.pickle','rb') as f:\n",
    "    data00 =  pickle.load(f)\n",
    "with gzip.open(modelpath + 'data00_X_train.pickle','rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with gzip.open(modelpath + 'data00_X_test.pickle','rb') as f:\n",
    "    X_test =  pickle.load(f)    \n",
    "with gzip.open(modelpath + 'data00_y_train.pickle','rb') as f:\n",
    "    y_train = pickle.load(f)    \n",
    "with gzip.open(modelpath + 'data00_y_test.pickle','rb') as f:\n",
    "    y_test = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 모델 회귀계수 확인하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression 이진분류 모델 불러오기\n",
    "with open(modelpath + 'logreg00.pkl', 'rb') as file:\n",
    "    logreg =  pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_test 의 컬럼명 확인하기\n",
    "\n",
    "X_test.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression 이진분류 모델의 회귀계수 확인하기\n",
    "\n",
    "logreg.coef_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터 형태 바꾸기\n",
    "\n",
    "coef = sum(logreg.coef_)\n",
    "coef"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression 이진분류 모델의 회귀계수 시각화 하기\n",
    "\n",
    "indices =  np.argsort(coef)  # 회귀계수 크기 순으로 정렬\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(X_test.columns, coef[indices], .35, color='orange', align='center')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices], fontsize=12)\n",
    "plt.xlabel('Coefficients (beta)', fontsize=12)\n",
    "plt.title('Feature Importances - Logistic Regression Coefficients\\n', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 모델 피처 중요도 분석하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 학습에 사용할 데이터를 로드하고 압축 풀기\n",
    "with gzip.open(modelpath + 'data00_X_train.pickle','rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with gzip.open(modelpath + 'data00_X_test.pickle','rb') as f:\n",
    "    X_test = pickle.load(f)    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest Classifier를 이용하여 모델 fitting 하기 \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc =  RandomForestClassifier(random_state = 42).fit(X_train, y_train) ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 저장하기\n",
    "\n",
    "pickle.dump(rfc, open(modelpath + 'rfc00.pkl', 'wb' ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "with open(modelpath + 'rfc00.pkl', 'rb') as file:\n",
    "    rfc =  pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest 이진분류 모델의 피처 중요도 확인하기 # MDI\n",
    "\n",
    "importances =  rfc.feature_importances_\n",
    "importances "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest 이진분류 모델의 피처 중요도 시각화 하기\n",
    "\n",
    "indices = np.argsort(importances)     # 중요도 크기 순으로 정렬\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.barh(X_test.columns, importances[indices], .35, color='purple', align='center')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices], fontsize=12)\n",
    "\n",
    "plt.xlabel('Relative Importance (MDI)', fontsize=12)\n",
    "plt.title('Feature Importances -- Random Forest Classifier (binary)\\n', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gradient Boosting 이진분류 모델 불러오기\n",
    "\n",
    "with open(modelpath + 'gbc00.pkl', 'rb') as file:\n",
    "    gbc = pickle.load(file) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gradient Boosting 이진분류 모델의 피처 중요도 확인하기\n",
    "\n",
    "importances =  gbc.feature_importances_\n",
    "importances  ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gradient Boosting 이진분류 모델의 피처 중요도 시각화 하기\n",
    "\n",
    "indices = np.argsort(importances)  # 중요도 크기 순으로 정렬\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.barh(X_test.columns, importances[indices], .35, color='lightgreen', align='center')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices], fontsize=12)\n",
    "\n",
    "plt.xlabel('Relative Importance (MDI)', fontsize=12)\n",
    "plt.title('Feature Importances -- Gradient Boosting Classifier (binary)\\n', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LightGBM 이진분류 모델 불러오기\n",
    "\n",
    "with open(modelpath + 'lgbm00.pkl', 'rb') as file:\n",
    "    lgbm =  pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LightGBM 이진분류 모델의 피처 중요도 확인하기 ## 피처별 분기한 회수\n",
    "\n",
    "importances =  lgbm.feature_importances_\n",
    "importances ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LightGBM 이진분류 모델의 피처 중요도 시각화 하기\n",
    "\n",
    "indices = np.argsort(importances)   # 중요도 크기 순으로 정렬\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.barh(X_test.columns, importances[indices], .35, color='lightblue', align='center')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices], fontsize=12)\n",
    "\n",
    "plt.xlabel('Feature Importance (# of splits)', fontsize=12)\n",
    "plt.title('Feature Importances -- LGBM Classifier (binary)\\n', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subplot을 이용하여 4개 이진분류 모델(logreg, gbc, rfc, lgbm)의 회귀계수 및 피처 중요도 시각화 비교하기\n",
    "\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1) \n",
    "indices_logreg = np.argsort(coef)   ###\n",
    "\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.barh(X_test.columns, coef[indices_logreg], .25, color='orange')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices_logreg])\n",
    "plt.xlabel('Coefficients (beta)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "importances_rfc = rfc.feature_importances_  ###\n",
    "indices_rfc = np.argsort(importances_rfc)  ###\n",
    "\n",
    "plt.title('Feature Importances -- Random Forest Classifier (binary)')\n",
    "plt.barh(X_test.columns, importances_rfc[indices_rfc], .25, color='purple')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices_rfc])\n",
    "plt.xlabel('Relative Importance (MDI)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "importances_gbc = gbc.feature_importances_  ###\n",
    "indices_gbc =  np.argsort(importances_gbc)  ###\n",
    "\n",
    "plt.title('Feature Importances -- Gradient Boosting Classifier (binary)')\n",
    "plt.barh(X_test.columns, importances_gbc[indices_gbc], .25, color='lightgreen')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices_gbc])\n",
    "plt.xlabel('Relative Importance (MDI)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "importances_lgbm = lgbm.feature_importances_  ###\n",
    "indices_lgbm = np.argsort(importances_lgbm)  ###\n",
    "\n",
    "plt.title('Feature Importances -- LGBM Classifier (binary)')\n",
    "plt.barh(X_test.columns, importances_lgbm[indices_lgbm], .25, color='lightblue')\n",
    "plt.yticks(X_test.columns, X_test.columns[indices_lgbm])\n",
    "plt.xlabel('Feature Importance (# of splits)')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 분석에 사용할 데이터 불러오기\n",
    "\n",
    "with gzip.open(modelpath + 'data01.pickle','rb') as f:\n",
    "    data01 =  pickle.load(f)\n",
    "with gzip.open(modelpath + 'data01_X_train.pickle','rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with gzip.open(modelpath + 'data01_X_test.pickle','rb') as f:\n",
    "    x_test =  pickle.load(f)\n",
    "with gzip.open(modelpath + 'data01_y_train.pickle','rb') as f:\n",
    "    y_train01 =  pickle.load(f)     ## \n",
    "with gzip.open(modelpath + 'data01_y_test.pickle','rb') as f:\n",
    "    y_test01 =   pickle.load(f)     ##"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델을 선언하고 fitting 하기\n",
    "\n",
    "rfc1 = RandomForestClassifier().fit(x_train, y_train01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x_test의 컬럼명 확인하기\n",
    "\n",
    "x_test.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest 다중분류 모델의 피처 중요도 확인하기\n",
    "importances =  rfc1.feature_importances_\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest 다중분류 모델의 피처 중요도 시각화 하기\n",
    "\n",
    "indices = np.argsort(importances)  # 중요도 크기 순으로 정렬\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(x_test.columns, importances[indices], .35, color='purple', align='center')\n",
    "plt.yticks(x_test.columns, x_test.columns[indices], fontsize=12)\n",
    "plt.xlabel('Relative Importance', fontsize=12)\n",
    "plt.title('Feature Importances -- Random Forest Classifier (multiclass)\\n', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 미리 저장한 LGBM 다중분류 모델 불러오기\n",
    "\n",
    "with open(modelpath + 'lgbm01.pkl', 'rb') as file:\n",
    "    lgbm1 =  pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LGBM 다중분류 모델의 피처 중요도 확인하기\n",
    "\n",
    "importances =  lgbm1.feature_importances_\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LGBM 다중분류 모델의 피처 중요도 시각화 하기\n",
    "\n",
    "indices =  np.argsort(importances)                  # 중요도 크기 순으로 정렬\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(x_test.columns, importances[indices], .35, color='lightblue', align='center')\n",
    "plt.yticks(x_test.columns, x_test.columns[indices], fontsize=12)\n",
    "\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Feature Importances -- LGBM Classifier (multiclass)\\n', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subplot을 이용하여 2개 이진분류 모델(rfc1, lgbm1)의 피처 중요도 시각화 비교하기\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1) \n",
    "importances_rfc = rfc1.feature_importances_  ###\n",
    "indices_rfc = np.argsort(importances_rfc)  ###\n",
    "\n",
    "plt.title('Feature Importances -- Random Forest Classifier (multiclass)')\n",
    "plt.barh(x_test.columns, importances_rfc[indices_rfc], .25, color='purple')\n",
    "plt.yticks(x_test.columns, x_test.columns[indices_rfc])\n",
    "plt.xlabel('Relative Importance (MDI)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "importances_lgbm = lgbm1.feature_importances_  ###\n",
    "indices_lgbm = np.argsort(importances_lgbm)  ###\n",
    "\n",
    "plt.title('Feature Importances -- LGBM Classifier (multiclass)')\n",
    "plt.barh(x_test.columns, importances_lgbm[indices_lgbm], .25, color='lightblue')\n",
    "plt.yticks(x_test.columns, x_test.columns[indices_lgbm])\n",
    "plt.xlabel('Feature Importance (# of splits)')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}